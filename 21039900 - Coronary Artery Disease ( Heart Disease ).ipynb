{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6a216f8",
   "metadata": {},
   "source": [
    "# Coronary Artery Disease Prediction Using ML \n",
    "\n",
    "Below are the steps and the classification of Coronary Artery Disease Prediction Using Naive Bayes Algorithm, K Nearest Neighbour Algorithm and Decision Tree Algorithm.\n",
    "\n",
    "The Dataset that was used in this project is [Heart Disease Patient Dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6e51a",
   "metadata": {},
   "source": [
    "# Importing Required Libraries\n",
    "The first step in formulating the solution is to import all the necessary libraries that should be optimized for procedures and operations during the development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.cm import rainbow\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve,auc, classification_report\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38911c0d",
   "metadata": {},
   "source": [
    "# Importing the Selected Dataset\n",
    "All the data stored in the csv file from the dataset will be imported and explored in the form of a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e309078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv(\"HeartDisease_Patients.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e4a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"HeartDisease_Patients.csv\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db0d38",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "Data exploration involves checking the dataset information, identifying missing values, and providing a summary of descriptive statistics to gain insights into the structure and characteristics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # describing the dataframe based on all of its columns and its respective data types and nnon-null cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad815c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() # Checking for missing values in the DataFrame 'df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f03957",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # Generating descriptive statistics for the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27ea84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() # Checking for missing values in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cea7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09baf591",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "Data visualization includes creating a heatmap to explore correlations among features, generating histograms for individual features, and visualizing the distribution of the target variable through a countplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the correlation of different attributes\n",
    "corrmat = df.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,10))\n",
    "#plot Heat Map\n",
    "g=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef435f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist() # Generating histograms for each numerical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dffb031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Seaborn style to 'whitegrid' and creating a count plot\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='target',data=df,palette='PuRd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f9e22",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "Data preprocessing involves creating dummy variables for categorical features, standardizing selected numerical features, and transforming the dataset to prepare it for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc89a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for categorical columns\n",
    "dataset= pd.get_dummies(df,columns=['gender','cp','fbs','restecg','exang','slope','ca','thal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d998bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a StandardScaler instance\n",
    "standardScaler=StandardScaler()\n",
    "columns_to_scale = ['age','trestbps','chol','thalach','oldpeak']\n",
    "dataset[columns_to_scale]=standardScaler.fit_transform(dataset[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c9af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1deea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the target variable 'y' and features 'x'\n",
    "y = df['target']\n",
    "x = df.drop('target',axis=1)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train,x_test,y_train, y_test= train_test_split(x,y,test_size=0.20,random_state=42)\n",
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02153a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.unique())\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6ef1ec",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = 'Naive Bayes'\n",
    "# Initializing a Naive Bayes model (Gaussian Naive Bayes) with variable 'nb'\n",
    "nb = GaussianNB()\n",
    "# Training the Naive Bayes model on the standardized training data\n",
    "model=nb.fit(x_train,y_train)\n",
    "# Predicting the target variable on the standardized test data\n",
    "nb_predict = nb.predict(x_test)\n",
    "# Calculating and displaying the confusion matrix for Naive Bayes predictions\n",
    "nb_conf_matrix = confusion_matrix(y_test,nb_predict)\n",
    "nb_acc_score = accuracy_score(y_test,nb_predict)\n",
    "print (\"Confussion Mtarix\")\n",
    "print (nb_conf_matrix)\n",
    "print (\"\\n\")\n",
    "print(\"Accuracy of Naive Bayes:\",nb_acc_score*100,'\\n')\n",
    "print (classification_report(y_test,nb_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3871565",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8587976c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying KNN Classifier & find the Value of 'K'\n",
    "knn_score =[]\n",
    "for k in range (1,21):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score= cross_val_score(knn,x,y,cv=10)\n",
    "    knn_score.append(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70519f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plot to visualize k-Nearest Neighbors classifier scores for different values of k\n",
    "fig= plt.figure(figsize=(18,10))\n",
    "plt.plot([k for k in range(1,21)],knn_score,color='red')\n",
    "for i in range (1,21):\n",
    "         plt.text(i,knn_score[i-1],(i,knn_score[i-1]))\n",
    "plt.xticks([i for i in range (1,21)]) \n",
    "plt.xlabel('Number of Neighbors (K)') \n",
    "plt.ylabel('score')\n",
    "plt.title ('k Neighbors Classifier Scores for Different K-Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193c5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a K-Neighbors Classifier model with k=19\n",
    "m2 = 'K-NeighborsClassifier'\n",
    "knn = KNeighborsClassifier(n_neighbors=19)\n",
    "# Training the K-Neighbors Classifier model on the standardized training data\n",
    "model=knn.fit(x_train,y_train)\n",
    "# Predicting the target variable on the standardized test data\n",
    "knn_predict = knn.predict(x_test)\n",
    "# Calculating and displaying the confusion matrix for K-Neighbors Classifier predictions\n",
    "knn_conf_matrix = confusion_matrix(y_test,knn_predict)\n",
    "knn_acc_score = accuracy_score(y_test,knn_predict)\n",
    "print (\"Confussion Mtarix\")\n",
    "print (knn_conf_matrix)\n",
    "print (\"\\n\")\n",
    "print(\"Accuracy of K-Neighbors Classifier:\",knn_acc_score*100,'\\n')\n",
    "print (classification_report(y_test,knn_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53969e25",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff065ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a Decision Tree Classifier with specified parameters\n",
    "m3 = 'DecisionTreeClassifier'\n",
    "dt = DecisionTreeClassifier(criterion='entropy',random_state=2,max_depth=6)\n",
    "# Training the Decision Tree Classifier model on the standardized training data\n",
    "dt.fit(x_train,y_train)\n",
    "# Predicting the target variable on the standardized test data\n",
    "dt_predict = dt.predict(52,1,0,125,212,0,1,168,0,1,2,2,3,0)\n",
    "dt_conf_matrix = confusion_matrix(y_test,dt_predict)\n",
    "dt_acc_score = accuracy_score(y_test,dt_predict)\n",
    "# Calculating and displaying the confusion matrix for Decision Tree Classifier predictions\n",
    "print (\"Confussion Mtarix\")\n",
    "print (dt_conf_matrix)\n",
    "print (\"\\n\")\n",
    "print(\"Accuracy of Decision Tree Classifier:\",dt_acc_score*100,'\\n')\n",
    "print (classification_report(y_test,dt_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8ca3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the XGBoost library using pip\n",
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1aa6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the XGBoost library\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee826c",
   "metadata": {},
   "source": [
    "# Feature Importance Visualization\n",
    "\n",
    "The plot visualizes the importance of attributes in the dataset, showcasing their respective weights derived from a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c453421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features (X_train) and target variable (y_train)\n",
    "X_train = df.drop('target', axis=1)  \n",
    "y_train = df['target']\n",
    "\n",
    "# Initializing an XGBoost\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = xgb_model.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "imp_feature = pd.DataFrame(list(feature_importances.items()), columns=['feature', 'importance'])\n",
    "imp_feature = imp_feature.sort_values(by='importance', ascending=True)  # Sort for horizontal bar chart\n",
    "\n",
    "# Plot feature importances\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "colors = [\"red\", \"green\", \"blue\", \"yellow\", \"magenta\", \"cyan\"]\n",
    "plt.title(\"Important Attributes\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Attributes\")\n",
    "plt.barh(imp_feature['feature'], imp_feature['importance'], color=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eae7341",
   "metadata": {},
   "source": [
    "# Receiver Operating Characteristic Curves (ROC)\n",
    "\n",
    "ROC Curves, short for Receiver Operating Characteristic Curves, provide a graphical representation of the performance of a classification model by illustrating the trade-off between sensitivity and specificity at various thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes ROC Curve\n",
    "nb_probs = nb.predict_proba(x_test)[:, 1]\n",
    "fpr_nb, tpr_nb, thresholds_nb = roc_curve(y_test, nb_probs)\n",
    "roc_auc_nb = auc(fpr_nb, tpr_nb)\n",
    "\n",
    "# K-Neighbors Classifier ROC Curve\n",
    "knn_probs = knn.predict_proba(x_test)[:, 1]\n",
    "fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, knn_probs)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "# Decision Tree Classifier ROC Curve\n",
    "dt_probs = dt.predict_proba(x_test)[:, 1]\n",
    "fpr_dt, tpr_dt, thresholds_dt = roc_curve(y_test, dt_probs)\n",
    "roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_nb, tpr_nb, color='orange', lw=2, label=f'Naive Bayes (AUC = {roc_auc_nb:.2f})')\n",
    "plt.plot(fpr_knn, tpr_knn, color='green', lw=2, label=f'K-Neighbors (AUC = {roc_auc_knn:.2f})')\n",
    "plt.plot(fpr_dt, tpr_dt, color='blue', lw=2, label=f'Decision Tree (AUC = {roc_auc_dt:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6666d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1521fb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3617878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9ca01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f892977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b4269e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f67bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d9689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c9975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c028ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ae483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fdb82c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5f86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a1765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee79731f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856dd731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
